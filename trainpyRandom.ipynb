{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "from torch.autograd import Variable\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from model import *\n",
    "import time\n",
    "import math\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.002\n",
    "content = None\n",
    "content_weight = 1e2\n",
    "style = None\n",
    "style_weight = 1\n",
    "epochs = 20000\n",
    "print_interval = 1000\n",
    "plot_interval = 1000\n",
    "output = 'outputR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_content (257, 1249)\n",
      "a_content_torch torch.Size([1, 1, 257, 1249])\n",
      "sr 22050\n",
      "------------\n",
      "a_style (257, 1249)\n",
      "a_style_torch torch.Size([1, 1, 257, 244])\n",
      "sr 22050\n"
     ]
    }
   ],
   "source": [
    "# WAV TO SPECTRUM BLOCK\n",
    "CONTENT_FILENAME = \"taycut.wav\"\n",
    "STYLE_FILENAME = \"boy18.wav\"\n",
    "\n",
    "a_content, src = wav2spectrum(CONTENT_FILENAME)\n",
    "a_style, srs = wav2spectrum(STYLE_FILENAME)\n",
    "\n",
    "a_content_torch = torch.from_numpy(a_content)[None, None, :, :] \n",
    "a_style_torch = torch.from_numpy(a_style)[None, None, :, :]\n",
    "\n",
    "\n",
    "print(\"a_content\", a_content.shape)\n",
    "print(\"a_content_torch\", a_content_torch.shape)\n",
    "\n",
    "print(\"sr\",src )\n",
    "print(\"------------\")\n",
    "print(\"a_style\", a_content.shape)\n",
    "print(\"a_style_torch\", a_style_torch.shape)\n",
    "\n",
    "print(\"sr\",src )\n",
    "\n",
    "# Output\n",
    "# a_content (257, 244)\n",
    "# a_content_torch torch.Size([1, 1, 257, 244])\n",
    "# sr 22050\n",
    "# ------------\n",
    "# a_style (257, 244)\n",
    "# a_style_torch torch.Size([1, 1, 257, 355])\n",
    "# sr 22050\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dando\\AppData\\Local\\Temp\\ipykernel_12284\\1072698933.py:8: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Display the Content spectrum\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(a_content, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar(label=\"Log Amplitude\")\n",
    "plt.title(\"Spectrogram of the Audio\")\n",
    "plt.xlabel(\"Time Frames\")\n",
    "plt.ylabel(\"Frequency Bins\")\n",
    "plt.show()\n",
    "plt.savefig(\"Content_Spectrum.png\")  # Save the plot as an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dando\\AppData\\Local\\Temp\\ipykernel_12284\\3122756499.py:8: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Display the Style spectrum\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(a_style, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar(label=\"Log Amplitude\")\n",
    "plt.title(\"Spectrogram of the Audio\")\n",
    "plt.xlabel(\"Time Frames\")\n",
    "plt.ylabel(\"Frequency Bins\")\n",
    "plt.show()\n",
    "plt.savefig(\"Style_Spectrum.png\")  # Save the plot as an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 257, 1249])\n",
      "torch.Size([1, 1, 257, 244])\n"
     ]
    }
   ],
   "source": [
    "if cuda:\n",
    "    a_content_torch = a_content_torch.cuda()\n",
    "    print(a_content_torch.shape)\n",
    "if cuda:\n",
    "    a_style_torch = a_style_torch.cuda()\n",
    "    print(a_style_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0241, 0.0081, 0.0096], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_content_torch[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 1), stride=(1, 1))\n",
       "  (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomCNN()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_C_var: torch.Size([1, 1, 257, 1249])\n",
      "a_S_var: torch.Size([1, 1, 257, 244])\n",
      "-------------\n",
      "a_C: torch.Size([1, 32, 255, 1249])\n",
      "a_S: torch.Size([1, 32, 255, 244])\n"
     ]
    }
   ],
   "source": [
    "# a_C_var = Variable(a_content_torch, requires_grad=False).float()\n",
    "# a_S_var = Variable(a_style_torch, requires_grad=False).float()\n",
    "\n",
    "a_C_var = a_content_torch.float()\n",
    "a_S_var = a_style_torch.float()\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "    a_C_var = a_C_var.cuda()\n",
    "    a_S_var = a_S_var.cuda()\n",
    "\n",
    "\n",
    "a_C = model(a_C_var) \n",
    "a_S = model(a_S_var) \n",
    "\n",
    "\n",
    "print(\"a_C_var:\", a_C_var.shape)\n",
    "print(\"a_S_var:\", a_S_var.shape)\n",
    "print(\"-------------\")\n",
    "print(\"a_C:\", a_C.shape)\n",
    "print(\"a_S:\", a_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_content_torch type <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a_C = model(a_C_var) \n",
    "a_S = model(a_S_var) \n",
    "\n",
    "print(\"a_content_torch type\", type(a_content_torch))\n",
    "\n",
    "a_G_var = torch.randn(a_content_torch.shape) * 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 255, 1249])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 257, 1249])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_G_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_G_var: torch.Size([1, 1, 257, 1249])\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "# a_G_var = Variable(torch.randn(a_content_torch.shape) * 1e-3)\n",
    "\n",
    "a_G_var = torch.randn(a_content_torch.shape) * 1e-3\n",
    "\n",
    "print(\"a_G_var:\",a_G_var.shape)\n",
    "\n",
    "\n",
    "if cuda:\n",
    "    a_G_var = a_G_var.cuda()\n",
    "\n",
    "\n",
    "a_G_var.requires_grad = True\n",
    "optimizer = torch.optim.Adam([a_G_var])\n",
    "\n",
    "print(\"optimizer:\", optimizer)\n",
    "# coefficient of content and style\n",
    "style_param = style_weight\n",
    "content_param = content_weight\n",
    "\n",
    "num_epochs = epochs\n",
    "print_every = print_interval\n",
    "plot_every = plot_interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 255, 1249])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_G = model(a_G_var)\n",
    "\n",
    "type(a_G)\n",
    "a_G.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 5.0% 1m 5s content_loss:0.700147 style_loss:0.175027 total_loss:0.875173\n",
      "2000 10.0% 2m 11s content_loss:0.546032 style_loss:0.051478 total_loss:0.597510\n",
      "3000 15.0% 3m 17s content_loss:0.476206 style_loss:0.050646 total_loss:0.526852\n",
      "4000 20.0% 4m 23s content_loss:0.449274 style_loss:0.052619 total_loss:0.501893\n",
      "5000 25.0% 5m 29s content_loss:0.441016 style_loss:0.053609 total_loss:0.494625\n",
      "6000 30.0% 6m 35s content_loss:0.439434 style_loss:0.053751 total_loss:0.493186\n",
      "7000 35.0% 7m 41s content_loss:0.439307 style_loss:0.053767 total_loss:0.493074\n",
      "8000 40.0% 8m 47s content_loss:0.439305 style_loss:0.053768 total_loss:0.493073\n",
      "9000 45.0% 9m 53s content_loss:0.439305 style_loss:0.053769 total_loss:0.493074\n",
      "10000 50.0% 10m 59s content_loss:0.439306 style_loss:0.053769 total_loss:0.493075\n",
      "11000 55.00000000000001% 12m 5s content_loss:0.439306 style_loss:0.053769 total_loss:0.493075\n",
      "12000 60.0% 13m 11s content_loss:0.439307 style_loss:0.053769 total_loss:0.493076\n",
      "13000 65.0% 14m 18s content_loss:0.439306 style_loss:0.053770 total_loss:0.493076\n",
      "14000 70.0% 15m 24s content_loss:0.439302 style_loss:0.053774 total_loss:0.493076\n",
      "15000 75.0% 16m 31s content_loss:0.439304 style_loss:0.053771 total_loss:0.493076\n",
      "16000 80.0% 17m 37s content_loss:0.439304 style_loss:0.053772 total_loss:0.493076\n",
      "17000 85.0% 18m 43s content_loss:0.439304 style_loss:0.053771 total_loss:0.493076\n",
      "18000 90.0% 19m 49s content_loss:0.439310 style_loss:0.053766 total_loss:0.493076\n",
      "19000 95.0% 20m 55s content_loss:0.439308 style_loss:0.053768 total_loss:0.493076\n",
      "20000 100.0% 22m 2s content_loss:0.439314 style_loss:0.053762 total_loss:0.493076\n"
     ]
    }
   ],
   "source": [
    "def trainModel(optimizer,current_loss):\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        a_G = model(a_G_var)\n",
    "\n",
    "        content_loss = content_param * compute_content_loss(a_C, a_G)\n",
    "        style_loss = style_param * compute_layer_style_loss(a_S, a_G)\n",
    "        loss = content_loss + style_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print\n",
    "        if epoch % print_every == 0:\n",
    "            print(\"{} {}% {} content_loss:{:4f} style_loss:{:4f} total_loss:{:4f}\".format(epoch,\n",
    "                                                                                        epoch / num_epochs * 100,\n",
    "                                                                                        timeSince(start),\n",
    "                                                                                        content_loss.item(),\n",
    "                                                                                        style_loss.item(), \n",
    "                                                                                        loss.item())\n",
    "                                                                                        )\n",
    "            current_loss += loss.item()\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if epoch % plot_every == 0:\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0\n",
    "    \n",
    "    return \n",
    "\n",
    "start = time.time()\n",
    "trainModel(optimizer,current_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 257, 1249])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_G_var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.68906351e-05\n",
      " 1.53408667e-04 1.17949826e-04]\n",
      "x.shape: (159744,)\n",
      "type(x)): <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "def librosa_write(outfile, x, sr):\n",
    "    if version.parse(librosa.__version__) < version.parse('0.8.0'):\n",
    "        librosa.output.write_wav(outfile, x, sr)\n",
    "    else:\n",
    "        soundfile.write(outfile, x, sr)\n",
    "\n",
    "\n",
    "def spectrum2wav(spectrum, sr, outfile):\n",
    "    # Return the all-zero vector with the same shape of `a_content`\n",
    "    a = np.exp(spectrum) - 1\n",
    "    p = 2 * np.pi * np.random.random_sample(spectrum.shape) - np.pi\n",
    "    \n",
    "    for i in range(50):\n",
    "        S = a * np.exp(1j * p)\n",
    "        x = librosa.istft(S)\n",
    "        p = np.angle(librosa.stft(x, n_fft=N_FFT))\n",
    "\n",
    "    print(\"x:\",x)\n",
    "    print(\"x.shape:\",x.shape)\n",
    "    print(\"type(x)):\",type(x))\n",
    "\n",
    "    librosa_write(outfile, x, sr)\n",
    "\n",
    "gen_spectrum = a_G_var.cpu().data.numpy().squeeze()\n",
    "gen_audio_C = output + \".wav\"\n",
    "spectrum2wav(gen_spectrum, src, gen_audio_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 1249)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_spectrum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.savefig('loss_curve.png')\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# we then use the 2nd column.\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.title(\"Content Spectrum\")\n",
    "plt.imsave('Content_SpectrumT.png', a_content[:400, :])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# we then use the 2nd column.\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.title(\"Style Spectrum\")\n",
    "plt.imsave('Style_SpectrumT.png', a_style[:400, :])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "# we then use the 2nd column.\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.title(\"CNN Voice Transfer Result\")\n",
    "plt.imsave('RanGen_SpectrumT.png', gen_spectrum[:400, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
